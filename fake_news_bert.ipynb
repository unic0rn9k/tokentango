{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d553d947-1083-461b-91d2-105b65b71bff",
   "metadata": {},
   "source": [
    "# Debug Bert notebook\n",
    "- [x] trivial case, with predicting shifted tokens, instead of mlm.\n",
    "- [x] trivial case, of classifying presence of marker token, at a random position.\n",
    "- [ ] Normalize frequency of labels across training and test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62d79629-e31f-483b-8001-9e8e3362dee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TokenTango\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tokentango"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbe96db1-833e-4ed7-addc-ba792134b666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam, AdamW\n",
    "from torch import nn, functional as F\n",
    "from plotly import express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools\n",
    "import math\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c577d1e0-1661-4fc0-9023-d380e16a2c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Number of GPUs: 2\n",
      "GPU 0: NVIDIA GeForce GTX 1080\n",
      "  Memory: 8.51 GB\n",
      "  CUDA Capability: 6.1\n",
      "GPU 1: NVIDIA GeForce GTX 1050 Ti\n",
      "  Memory: 4.23 GB\n",
      "  CUDA Capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f\"Number of GPUs: {num_gpus}\")\n",
    "for i in range(num_gpus):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    print(f\"  Memory: {torch.cuda.get_device_properties(i).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"  CUDA Capability: {torch.cuda.get_device_properties(i).major}.{torch.cuda.get_device_properties(i).minor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "795d072a-db2e-4197-90de-7fb5242be9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237f08ba-972d-4825-991c-1cca902e25cf",
   "metadata": {},
   "source": [
    "```py\n",
    "# 1. Embeddings padding_idx = 0, might conflict with cls, or other tokens? (model.py)\n",
    "# 2. xs, masks and cls classes are all made with seperate calls to train_test_split (in bert_from_scratch.py)\n",
    "#    so maybe the cls' dont match the text\n",
    "num_samples = 2000\n",
    "\n",
    "xs = torch.randint(low=1, high=10, size=(num_samples,5), dtype=torch.int32)\n",
    "xs = torch.cat([torch.zeros(num_samples, 1, dtype=torch.int), xs], dim=1).to(device)\n",
    "\n",
    "ys = xs.clone()\n",
    "cls_label = [float(any(n == 1 for n in xs[i,:])) for i in range(num_samples)]\n",
    "\n",
    "split_at = int(0.2 * num_samples)\n",
    "\n",
    "train_x = xs[:split_at, :]\n",
    "train_y = ys[:split_at, :]\n",
    "train_cls = cls_label[:split_at]\n",
    "\n",
    "test_x = xs[split_at:, :]\n",
    "test_y = ys[split_at:, :]\n",
    "test_cls = cls_label[split_at:]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e94ac0e-b81b-48fb-8e2b-0e14fd1ea092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bigbox/Projects/tokentango/src/tokentango/fake_news.py:15: DtypeWarning: Columns (0,1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  large_set = pd.read_csv(\"995,000_rows.csv\").sample(frac=frac).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "new_labels\n",
      "reliable    330584\n",
      "fake        166071\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bigbox/Projects/tokentango/src/tokentango/fake_news.py:63: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  large_set = large_set.groupby('new_labels').apply(lambda x: x.sample(min_count, random_state=42)).sample(frac=1).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "#train_x = tokentango.fake_news.train_mlm\n",
    "#train_y = tokentango.fake_news.train_x\n",
    "#train_cls = tokentango.fake_news.train_y\n",
    "train_x, train_y, train_cls, test_x, test_y, test_cls = tokentango.fake_news.load_data(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778d48e6-ba46-4250-bc04-d05be437b819",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.to(device)\n",
    "train_y = train_y.to(device)\n",
    "train_cls = train_cls.to(device)\n",
    "\n",
    "test_x = torch.tensor(test_x).to(device)\n",
    "test_y = torch.tensor(test_y).to(device)\n",
    "test_cls = torch.tensor(test_cls).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c81cf9-22f7-4d76-be83-a5f2dd1882b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_in_bytes = train_x.element_size() * train_x.numel() + train_y.element_size() * train_y.numel() + train_cls.element_size() * train_cls.numel()\n",
    "size_in_bytes2 = test_x.element_size() * test_x.numel() + test_y.element_size() * test_y.numel() + test_cls.element_size() * test_cls.numel()\n",
    "size_in_gb = (size_in_bytes + size_in_bytes2) / (1024 ** 3)\n",
    "\n",
    "print(f\"Tensor size: {size_in_gb:.4f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1257b0-9e78-4b61-9b11-a1724d0250aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current memory usage\n",
    "print(torch.cuda.memory_allocated() / 1024**3, \"GB allocated\")\n",
    "print(torch.cuda.memory_reserved() / 1024**3, \"GB reserved by caching allocator\")\n",
    "\n",
    "# Optional: summary of tensors by type\n",
    "from torchsummary import summary\n",
    "\n",
    "# Or more advanced: use torch.cuda.memory_summary\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805b6699-2264-475b-9a36-0368d7265ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tokentango.BertClassifier(300, 40000, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f2ce3f-f953-4f75-9b09-aa8803779ea0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# 1. embedding padding_idx (from model.py) should probably be set to pad_token_id (from fake_news.py)\n",
    "# 3. Maybe change named_parameters to parameters? (also in bert_from_scratch.py)\n",
    "#optimizer = AdamW(model.parameters(), lr = 1e-4, eps = 1e-8)\n",
    "\n",
    "result = tokentango.train.train(model, train_x, train_y, train_cls, test_x, test_y, test_cls, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e8ee132-286b-4707-be32-85dea46841e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(84.9171936163806)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([tokentango.train.test_accuracy(model, test_x, test_y, test_cls, device) for _ in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c872dc-a8fd-439d-bec1-563fd63ac298",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(mlm_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5ee076-e864-47b2-8619-160caad3c959",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(cls_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158d56c6-55a2-4f9a-9a50-0d2ff75fbddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acea8886-d0c7-4a10-9349-33ba0c874b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for idx in range(len(train_cls)):\n",
    "    x = train_y[idx:idx+1,:]\n",
    "    hidden = model.hidden(x)\n",
    "    output = model.classify(hidden)\n",
    "    #print(output.cpu().detach().item(), cls_label[idx:idx+1], x.cpu().detach().tolist())\n",
    "    #correct += int((output.cpu().detach().item()<0.5) == bool(np.signbit(cls_label[idx:idx+1][0])))\n",
    "    correct += int(np.sign(output.cpu().detach().item()) == np.sign(train_cls[idx].cpu()))\n",
    "\n",
    "accuracy = correct / len(test_cls)*100\n",
    "print(f'{accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c04c45b-867d-46da-9500-7fef86dc3387",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputs = []\n",
    "num_samples = len(test_cls)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for idx in range(0, num_samples):\n",
    "        x = train_x[idx:idx+1,:]\n",
    "        hidden = model.hidden(x)\n",
    "        output = model.classify(hidden)\n",
    "        outputs.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff53e82-e900-4912-8959-8ae1abc1fb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = torch.sign(torch.cat(outputs))\n",
    "\n",
    "predicted_values = torch.round(outputs)\n",
    "predicted_values = predicted_values.cpu().view(-1).numpy()\n",
    "true_values = test_cls.cpu().numpy()\n",
    "label_values = [\"reliabel\", \"fake\"]\n",
    "\n",
    "test_accuracy = np.sum(predicted_values == true_values) / len(true_values)\n",
    "print (\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "print(classification_report(true_values, predicted_values, target_names=[str(l) for l in label_values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7438ba9f-17a2-45f0-b618-8e9df4784e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "cm_test = confusion_matrix(true_values, predicted_values)\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "#plt.figure(figsize=(6,6))\n",
    "#plot_confusion_matrix(cm_test, classes=label_values, title='Confusion Matrix - Test Dataset')\n",
    "plt.figure(figsize=(6,6))\n",
    "plot_confusion_matrix(cm_test, classes=label_values, title='Confusion Matrix - Test Dataset', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0977098d-9a4c-40b2-8282-166b722aa8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(n == 1 for n in predicted_values))\n",
    "print(sum(n == -1 for n in predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb959193-3b5f-4434-b4de-0b13e0be2ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(n == 1 for n in train_cls))\n",
    "print(sum(n == -1 for n in train_cls))\n",
    "print(sum(n == 1 for n in test_cls))\n",
    "print(sum(n == -1 for n in test_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691421e3-886d-4820-b01e-ff153225c43b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67853909-a5be-46a6-8458-9cac749bcb9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17d40c4-270f-48ea-85f6-f699856e405d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
